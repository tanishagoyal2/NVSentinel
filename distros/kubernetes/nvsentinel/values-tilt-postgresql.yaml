# Copyright (c) 2025, NVIDIA CORPORATION.  All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# SECURITY NOTE: This configuration uses certificate-based authentication for PostgreSQL.
#
# Authentication method:
#   - PostgreSQL server uses TLS certificates generated by cert-manager
#   - Applications authenticate using client certificates
#   - No passwords are required or used for database connections
#
# Certificates are automatically generated and managed by cert-manager.

global:
  dryRun: false
  kubeVersion: 1.31.0
  clusterType: standalone # Required for cert-manager resources
  # Keep legacy resource naming for Tilt compatibility
  # Tiltfile expects "platform-connectors" resource name
  useLegacyResourceNames: true
  # Configure PostgreSQL as the datastore provider
  datastore:
    provider: "postgresql"
    connection:
      host: "nvsentinel-postgresql.nvsentinel.svc.cluster.local"
      port: 5432
      database: "nvsentinel"
      username: "postgresql"
      sslmode: "require"
      sslcert: "/etc/ssl/client-certs/tls.crt"
      sslkey: "/etc/ssl/client-certs/tls.key"
      sslrootcert: "/etc/ssl/client-certs/ca.crt"
  # Disable MongoDB store when using PostgreSQL
  mongodbStore:
    enabled: false
# Enable PostgreSQL subchart
postgresql:
  enabled: true
  # Global image configuration for all containers including init containers
  global:
    imageRegistry: "docker.io"
    imagePullSecrets: []
  # Development-friendly configuration
  architecture: standalone
  replicaCount: 1
  nodeSelector:
    node-role.kubernetes.io/control-plane: ""
  tolerations:
    - operator: Exists
  image:
    registry: "docker.io"
    repository: "bitnamilegacy/postgresql"
    tag: "16.4.0-debian-12-r11"
    pullPolicy: "IfNotPresent"
    pullSecrets:
      - nvidia-ngcuser-pull-secret
  # Reduced resource requirements for local development
  resources:
    requests:
      cpu: "100m"
      memory: "256Mi"
    limits:
      cpu: "500m"
      memory: "512Mi"
  # PostgreSQL-specific configuration with certificate authentication
  auth:
    postgresPassword: "unused" # Not used with certificate auth
    username: "postgresql"
    database: "nvsentinel"
  primary:
    persistence:
      enabled: true
      size: 1Gi
      storageClass: ""
    # Enable TLS for PostgreSQL server
    tls:
      enabled: true
      certificatesSecret: "postgresql-server-cert"
      certFilename: "tls.crt"
      certKeyFilename: "tls.key"
      certCAFilename: "ca.crt"
    # Require client certificates
    pgHbaConfiguration: |-
      # TYPE  DATABASE        USER            ADDRESS                 METHOD
      hostssl all             all             0.0.0.0/0               cert
      hostssl all             all             ::/0                    cert
      local   all             all                                     trust
      host    all             all             127.0.0.1/32            trust
      host    all             all             ::1/128                 trust
    # Initialize the database with required tables and schema
    #
    # IMPORTANT: This schema is automatically generated from docs/postgresql-schema.sql
    #
    # DO NOT edit this initdb script directly!
    # To update the schema:
    #   1. Edit: docs/postgresql-schema.sql
    #   2. Run:  make update-helm-postgres-schema
    #   3. Test: make validate-postgres-schema
    #   4. Commit both files together
    #
    initdb:
      scripts:
        00-init.sql: |-
          -- Copyright (c) 2025, NVIDIA CORPORATION.  All rights reserved.
          --
          -- Licensed under the Apache License, Version 2.0 (the "License");
          -- you may not use this file except in compliance with the License.
          -- You may obtain a copy of the License at
          --
          --     http://www.apache.org/licenses/LICENSE-2.0
          --
          -- Unless required by applicable law or agreed to in writing, software
          -- distributed under the License is distributed on an "AS IS" BASIS,
          -- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          -- See the License for the specific language governing permissions and
          -- limitations under the License.

          -- ============================================================================
          -- PostgreSQL Schema for NVSentinel DataStore
          -- ============================================================================
          --
          -- IMPORTANT: This is the canonical source of truth for PostgreSQL schema!
          --
          -- This schema is also embedded in:
          --   â€¢ distros/kubernetes/nvsentinel/values-tilt-postgresql.yaml
          --
          -- When updating this file, you MUST also update the Helm values file:
          --   1. Make changes to this file (docs/postgresql-schema.sql)
          --   2. Run: make update-helm-postgres-schema
          --   3. Validate: make validate-postgres-schema
          --   4. Commit both files together
          --
          -- This schema supports both MaintenanceEvent and HealthEvent storage
          -- with JSON document storage for flexibility and PostgreSQL benefits
          -- ============================================================================

          -- Extension for JSON operations and UUID generation
          CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

          -- ====================================================================
          -- MAINTENANCE EVENTS (CSP Health Monitor)
          -- ====================================================================

          CREATE TABLE IF NOT EXISTS maintenance_events (
              -- Primary key
              id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),

              -- Core event identification (extracted for indexing)
              event_id VARCHAR(255) UNIQUE NOT NULL,
              csp VARCHAR(50) NOT NULL,
              cluster_name VARCHAR(255) NOT NULL,
              node_name VARCHAR(255),
              status VARCHAR(50) NOT NULL,
              csp_status VARCHAR(50),

              -- Time fields (extracted for efficient querying)
              scheduled_start_time TIMESTAMPTZ,
              actual_end_time TIMESTAMPTZ,
              event_received_timestamp TIMESTAMPTZ NOT NULL,
              last_updated_timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),

              -- Full document storage (JSON)
              document JSONB NOT NULL,

              -- Metadata
              created_at TIMESTAMPTZ DEFAULT NOW(),
              updated_at TIMESTAMPTZ DEFAULT NOW()
          );

          -- Indexes for maintenance_events
          CREATE INDEX IF NOT EXISTS idx_maintenance_events_event_id ON maintenance_events(event_id);
          CREATE INDEX IF NOT EXISTS idx_maintenance_events_csp_cluster ON maintenance_events(csp, cluster_name);
          CREATE INDEX IF NOT EXISTS idx_maintenance_events_node_status ON maintenance_events(node_name, status);
          CREATE INDEX IF NOT EXISTS idx_maintenance_events_status_scheduled ON maintenance_events(status, scheduled_start_time) WHERE scheduled_start_time IS NOT NULL;
          CREATE INDEX IF NOT EXISTS idx_maintenance_events_status_actual_end ON maintenance_events(status, actual_end_time) WHERE actual_end_time IS NOT NULL;
          CREATE INDEX IF NOT EXISTS idx_maintenance_events_received_desc ON maintenance_events(csp, cluster_name, event_received_timestamp DESC);
          CREATE INDEX IF NOT EXISTS idx_maintenance_events_last_updated ON maintenance_events(last_updated_timestamp DESC);
          CREATE INDEX IF NOT EXISTS idx_maintenance_events_csp_status ON maintenance_events(csp_status) WHERE csp_status IS NOT NULL;

          -- GIN index for flexible JSON querying
          CREATE INDEX IF NOT EXISTS idx_maintenance_events_document_gin ON maintenance_events USING GIN (document);

          -- ====================================================================
          -- HEALTH EVENTS (Platform Connectors)
          -- ====================================================================

          CREATE TABLE IF NOT EXISTS health_events (
              -- Primary key
              id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),

              -- Core event identification (extracted for indexing)
              node_name VARCHAR(255) NOT NULL,
              event_type VARCHAR(100),
              severity VARCHAR(50),
              recommended_action VARCHAR(100),

              -- Status tracking
              node_quarantined VARCHAR(50),
              user_pods_eviction_status VARCHAR(50) DEFAULT 'NotStarted',
              user_pods_eviction_message TEXT,
              fault_remediated BOOLEAN,
              last_remediation_timestamp TIMESTAMPTZ,

              -- Full document storage (JSON)
              document JSONB NOT NULL,

              -- Metadata
              created_at TIMESTAMPTZ DEFAULT NOW(),
              updated_at TIMESTAMPTZ DEFAULT NOW()
          );

          -- Indexes for health_events
          CREATE INDEX IF NOT EXISTS idx_health_events_node_name ON health_events(node_name);
          CREATE INDEX IF NOT EXISTS idx_health_events_node_type ON health_events(node_name, event_type);
          CREATE INDEX IF NOT EXISTS idx_health_events_quarantined ON health_events(node_quarantined) WHERE node_quarantined IS NOT NULL;
          CREATE INDEX IF NOT EXISTS idx_health_events_eviction_status ON health_events(user_pods_eviction_status);
          CREATE INDEX IF NOT EXISTS idx_health_events_created_desc ON health_events(created_at DESC);
          CREATE INDEX IF NOT EXISTS idx_health_events_updated_desc ON health_events(updated_at DESC);

          -- GIN index for flexible JSON querying
          CREATE INDEX IF NOT EXISTS idx_health_events_document_gin ON health_events USING GIN (document);

          -- ====================================================================
          -- CHANGE TRACKING (For polling-based change streams)
          -- ====================================================================

          CREATE TABLE IF NOT EXISTS datastore_changelog (
              id BIGSERIAL PRIMARY KEY,
              table_name VARCHAR(100) NOT NULL,
              record_id UUID NOT NULL,
              operation VARCHAR(20) NOT NULL, -- INSERT, UPDATE, DELETE
              old_values JSONB,
              new_values JSONB,
              changed_at TIMESTAMPTZ DEFAULT NOW(),
              processed BOOLEAN DEFAULT FALSE
          );

          -- Index for change tracking
          CREATE INDEX IF NOT EXISTS idx_changelog_unprocessed ON datastore_changelog(changed_at) WHERE processed = FALSE;
          CREATE INDEX IF NOT EXISTS idx_changelog_table_record ON datastore_changelog(table_name, record_id);

          -- ====================================================================
          -- RESUME TOKENS (For change stream compatibility)
          -- ====================================================================

          CREATE TABLE IF NOT EXISTS resume_tokens (
              client_name VARCHAR(255) PRIMARY KEY,
              resume_token JSONB NOT NULL,
              last_updated TIMESTAMPTZ DEFAULT NOW()
          );

          -- ====================================================================
          -- TRIGGERS FOR CHANGE TRACKING
          -- ====================================================================

          -- Function to log changes
          CREATE OR REPLACE FUNCTION log_table_changes()
          RETURNS TRIGGER AS $$
          BEGIN
              IF TG_OP = 'DELETE' THEN
                  INSERT INTO datastore_changelog (table_name, record_id, operation, old_values)
                  VALUES (TG_TABLE_NAME, OLD.id, TG_OP, to_jsonb(OLD));
                  RETURN OLD;
              ELSIF TG_OP = 'UPDATE' THEN
                  INSERT INTO datastore_changelog (table_name, record_id, operation, old_values, new_values)
                  VALUES (TG_TABLE_NAME, NEW.id, TG_OP, to_jsonb(OLD), to_jsonb(NEW));
                  RETURN NEW;
              ELSIF TG_OP = 'INSERT' THEN
                  INSERT INTO datastore_changelog (table_name, record_id, operation, new_values)
                  VALUES (TG_TABLE_NAME, NEW.id, TG_OP, to_jsonb(NEW));
                  RETURN NEW;
              END IF;
              RETURN NULL;
          END;
          $$ LANGUAGE plpgsql;

          -- Drop triggers if they exist (for idempotent schema application)
          DROP TRIGGER IF EXISTS maintenance_events_changes ON maintenance_events;
          DROP TRIGGER IF EXISTS health_events_changes ON health_events;

          -- Apply triggers
          CREATE TRIGGER maintenance_events_changes
              AFTER INSERT OR UPDATE OR DELETE ON maintenance_events
              FOR EACH ROW EXECUTE FUNCTION log_table_changes();

          CREATE TRIGGER health_events_changes
              AFTER INSERT OR UPDATE OR DELETE ON health_events
              FOR EACH ROW EXECUTE FUNCTION log_table_changes();

          -- ====================================================================
          -- HELPER FUNCTIONS
          -- ====================================================================

          -- Function to clean old changelog entries (call periodically)
          CREATE OR REPLACE FUNCTION cleanup_changelog(retention_days INTEGER DEFAULT 7)
          RETURNS INTEGER AS $$
          DECLARE
              deleted_count INTEGER;
          BEGIN
              DELETE FROM datastore_changelog
              WHERE changed_at < NOW() - INTERVAL '1 day' * retention_days
              AND processed = TRUE;

              GET DIAGNOSTICS deleted_count = ROW_COUNT;
              RETURN deleted_count;
          END;
          $$ LANGUAGE plpgsql;

          -- Function to mark changelog entries as processed
          CREATE OR REPLACE FUNCTION mark_changelog_processed(max_id BIGINT)
          RETURNS INTEGER AS $$
          DECLARE
              updated_count INTEGER;
          BEGIN
              UPDATE datastore_changelog
              SET processed = TRUE
              WHERE id <= max_id AND processed = FALSE;

              GET DIAGNOSTICS updated_count = ROW_COUNT;
              RETURN updated_count;
          END;
          $$ LANGUAGE plpgsql;
  # Enable metrics (matching MongoDB configuration)
  metrics:
    enabled: true
    image:
      registry: docker.io
      repository: bitnamilegacy/postgres-exporter
      tag: 0.15.0-debian-12-r31
  tls:
    enabled: true
    autoGenerated: false
    certificatesSecret: "postgresql-server-cert"
    certFilename: "tls.crt"
    certKeyFilename: "tls.key"
    certCAFilename: "ca.crt"
    # TLS init container image configuration
    image:
      registry: "docker.io"
      repository: "bitnamilegacy/os-shell"
      tag: "12-debian-12-r30"
      pullPolicy: "IfNotPresent"
      pullSecrets:
        - nvidia-ngcuser-pull-secret
# Disable MongoDB-specific configuration
mongodb-store:
  mongodb:
    enabled: false
