# Copyright (c) 2025, NVIDIA CORPORATION.  All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

global:
  dryRun: false
  kubeVersion: 1.31.0

  # NOTE: Datastore configuration is provided by:
  # - values-tilt-mongodb.yaml (default, when USE_POSTGRESQL is not set)
  # - values-tilt-postgresql.yaml (when USE_POSTGRESQL=1)
  # This ensures proper configuration for both database backends

  nodeSelector: {}
  
  tolerations: 
  - operator: Exists
  
  affinity: {}
  
  systemNodeSelector:
    node-role.kubernetes.io/control-plane: ""
  
  systemNodeTolerations:
  - operator: Exists

  gpuHealthMonitor:
    enabled: true

  healthEventsAnalyzer:
    enabled: true

  faultQuarantine:
    enabled: true

  nodeDrainer:
    enabled: true

  faultRemediation:
    enabled: true

  dcaHealthMonitor:
    enabled: false

  cspHealthMonitor:
    enabled: false

  syslogHealthMonitor:
    enabled: true
    xidSideCar:
      enabled: false

  inclusterFileServer:
    enabled: true
  
  janitor:
    enabled: true

  mongodbStore:
    enabled: true

  metadataCollector:
    enabled: false

  kubernetesObjectMonitor:
    enabled: true

  eventExporter:
    enabled: true
  
  metricsPort: 2112

mongodb-store:
  useBitnami: true
  usePerconaOperator: false
  
  job:
    nodeSelector:
      node-role.kubernetes.io/control-plane: ""
    tolerations:
      - operator: Exists

  psmdb-operator:
    nodeSelector:
      node-role.kubernetes.io/control-plane: ""
    tolerations:
      - operator: Exists

  psmdb-db:
    nameOverride: mongodb
    fullnameOverride: mongodb
    replsets:
      rs0:
        name: rs0
        size: 3
        configuration: |
          setParameter:
            authenticationMechanisms: "MONGODB-X509,SCRAM-SHA-256,SCRAM-SHA-1"
        replsetOverrides:
          mongodb-rs0-0:
            priority: 3
          mongodb-rs0-1:
            priority: 1
          mongodb-rs0-2:
            priority: 1
        volumeSpec:
          pvc:
            resources:
              requests:
                storage: "1Gi"
        nodeSelector:
          node-role.kubernetes.io/control-plane: ""
        tolerations:
          - operator: Exists
        podDisruptionBudget:
          maxUnavailable: 1
    
    sharding:
      enabled: false
      
    logcollector:
      enabled: false
    
    tls:
      mode: requireTLS

    secrets:
      keyFile: mongodb-keyfile
      encryptionKey: mongodb-encryption-key
    
    backup:
      enabled: false
      storages: {}
      tasks: []
      volumeMounts: []
    
    finalizers: []

  psmdb:
    helperImages:
      kubectl:
        repository: docker.io/lachlanevenson/k8s-kubectl
        tag: "v1.25.4"
        pullPolicy: IfNotPresent
      mongosh:
        repository: ghcr.io/rtsp/docker-mongosh
        tag: "2.5.2"
        pullPolicy: IfNotPresent
  
  # Bitnami MongoDB configuration
  mongodb:
    replicaCount: 1
    nodeSelector:
      node-role.kubernetes.io/control-plane: ""
    
    tolerations:
    - operator: Exists

    jobTolerations:
    - operator: Exists

    image:
      registry: "docker.io"
      repository: "bitnamilegacy/mongodb"
      tag: "8.0.3-debian-12-r1"
      pullPolicy: "IfNotPresent"

    tls:
      replicaset:
        existingSecrets:
          - "mongo-server-cert-0"
      
      image:
        registry: "docker.io"
        repository: "bitnamilegacy/nginx"
        tag: "1.27.2-debian-12-r2"
        pullPolicy: "IfNotPresent"

    metrics:
      enabled: true
      image:
        registry: docker.io
        repository: bitnamilegacy/mongodb-exporter
        tag: 0.41.2-debian-12-r1

# Subchart-specific configuration for incluster-file-server
incluster-file-server:
  # Disable log cleanup in Tilt - the cleanup image may not be available
  logCleanup:
    enabled: false

# Override log levels for all modules during testing
fault-quarantine:
  logLevel: debug

  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/name: kwok
        namespaceSelector:
          matchLabels:
            kubernetes.io/metadata.name: kube-system
        topologyKey: kubernetes.io/hostname

fault-remediation:
  logLevel: debug

  logCollector:
    enabled: true
    image:
      repository: localhost:5001/ghcr.io_nvidia_nvsentinel_log-collector
      tag: latest  
      pullPolicy: Always 
    timeout: "10s"  # Short timeout for faster testing (production default: "10m")
    env:
      MOCK_MODE: "true"  
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/name: kwok
        namespaceSelector:
          matchLabels:
            kubernetes.io/metadata.name: kube-system
        topologyKey: kubernetes.io/hostname


node-drainer:
  logLevel: debug

  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/name: kwok
        namespaceSelector:
          matchLabels:
            kubernetes.io/metadata.name: kube-system
        topologyKey: kubernetes.io/hostname


health-events-analyzer:
  logLevel: debug

  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/name: kwok
        namespaceSelector:
          matchLabels:
            kubernetes.io/metadata.name: kube-system
        topologyKey: kubernetes.io/hostname

janitor:
  webhook:
    certIssuer: "janitor-selfsigned-issuer"

labeler:
  logLevel: debug
  # Test kata label override with the annotation present on kata test nodes
  # Uncomment to test custom kata detection:
  # kataLabelOverride: "io.katacontainers.config.runtime.oci_runtime"

csp-health-monitor:
  logLevel: debug
  quarantineTriggerEngine:
    logLevel: debug

# Enable node metadata enrichment for testing
platformConnector:
  nodeMetadata:
    enabled: true

kubernetes-object-monitor:
  logLevel: debug

  policies:
    - name: node-test-condition
      enabled: true
      resource:
        group: ""
        version: v1
        kind: Node
      predicate:
        expression: |
          resource.status.conditions.filter(c, c.type == "TestCondition" && c.status == "False").size() > 0
      healthEvent:
        componentClass: Node
        isFatal: false
        message: "Node test condition is not ready"
        recommendedAction: CONTACT_SUPPORT
        errorCode:
          - NODE_TEST_CONDITION_NOT_READY

  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/name: kwok
        namespaceSelector:
          matchLabels:
            kubernetes.io/metadata.name: kube-system
        topologyKey: kubernetes.io/hostname

event-exporter:
  replicaCount: 1

  image:
    repository: ghcr.io/nvidia/nvsentinel/event-exporter
    pullPolicy: IfNotPresent

  podAnnotations: {}

  resources:
    limits:
      cpu: "500m"
      memory: "512Mi"
    requests:
      cpu: "100m"
      memory: "128Mi"

  oidcSecretName: "event-exporter-oidc-secret"

  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/name: kwok
        namespaceSelector:
          matchLabels:
            kubernetes.io/metadata.name: kube-system
        topologyKey: kubernetes.io/hostname

  exporter:
    metadata:
      cluster: "tilt-test-cluster"
      environment: "development"
      tilt_test: "true"

    sink:
      endpoint: "http://event-exporter-mock.nvsentinel.svc.cluster.local:8443/events"
      timeout: "30s"
      insecureSkipVerify: true

    oidc:
      tokenUrl: "http://event-exporter-mock.nvsentinel.svc.cluster.local:8443/token"
      clientId: "tilt-test-client"
      scope: "test-scope"
      insecureSkipVerify: true

    backfill:
      enabled: true
      maxAge: "1h"
      maxEvents: 10000
      batchSize: 100
      rateLimit: 100

    resumeToken:
      database: "nvsentinel"
      collection: "resumetokens"

    failureHandling:
      maxRetries: 3
      initialBackoff: "1s"
      maxBackoff: "10s"
      backoffMultiplier: 2.0
