// Copyright (c) 2025, NVIDIA CORPORATION.  All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.10
// 	protoc        v6.33.0
// source: device/v1alpha1/gpu.proto

package v1alpha1

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	timestamppb "google.golang.org/protobuf/types/known/timestamppb"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// Gpu represents a single GPU resource.
//
// Its structure follows the Kubernetes Resource Model pattern (Spec/Status).
type Gpu struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// name is the unique logical identifier of the GPU resource.
	//
	// This is typically the lowercased GPU UUID, but may take other forms.
	//
	// Example: "gpu-a1b2c3d4-e5f6-a7b8-c9d0-e1f2a3b4c5d6"
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// spec defines the identity and desired attributes of the GPU resource.
	Spec *GpuSpec `protobuf:"bytes,2,opt,name=spec,proto3" json:"spec,omitempty"`
	// status contains the most recently observed state of the GPU resource.
	// This data may lag slightly behind the actual on-device state.
	Status        *GpuStatus `protobuf:"bytes,3,opt,name=status,proto3" json:"status,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Gpu) Reset() {
	*x = Gpu{}
	mi := &file_device_v1alpha1_gpu_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Gpu) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Gpu) ProtoMessage() {}

func (x *Gpu) ProtoReflect() protoreflect.Message {
	mi := &file_device_v1alpha1_gpu_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Gpu.ProtoReflect.Descriptor instead.
func (*Gpu) Descriptor() ([]byte, []int) {
	return file_device_v1alpha1_gpu_proto_rawDescGZIP(), []int{0}
}

func (x *Gpu) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *Gpu) GetSpec() *GpuSpec {
	if x != nil {
		return x.Spec
	}
	return nil
}

func (x *Gpu) GetStatus() *GpuStatus {
	if x != nil {
		return x.Status
	}
	return nil
}

// GpuList is a collection of GPU resources.
type GpuList struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// items is the list of GPU resources.
	Items         []*Gpu `protobuf:"bytes,1,rep,name=items,proto3" json:"items,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GpuList) Reset() {
	*x = GpuList{}
	mi := &file_device_v1alpha1_gpu_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GpuList) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GpuList) ProtoMessage() {}

func (x *GpuList) ProtoReflect() protoreflect.Message {
	mi := &file_device_v1alpha1_gpu_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GpuList.ProtoReflect.Descriptor instead.
func (*GpuList) Descriptor() ([]byte, []int) {
	return file_device_v1alpha1_gpu_proto_rawDescGZIP(), []int{1}
}

func (x *GpuList) GetItems() []*Gpu {
	if x != nil {
		return x.Items
	}
	return nil
}

// GpuSpec describes the identity and desired attributes of the GPU.
type GpuSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// uuid is the physical hardware UUID of this GPU.
	//
	// Format: 'GPU-<hex-string>' (e.g., 'GPU-a1b2c3d4-e5f6-a7b8-c9d0-e1f2a3b4c5d6').
	Uuid          string `protobuf:"bytes,1,opt,name=uuid,proto3" json:"uuid,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GpuSpec) Reset() {
	*x = GpuSpec{}
	mi := &file_device_v1alpha1_gpu_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GpuSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GpuSpec) ProtoMessage() {}

func (x *GpuSpec) ProtoReflect() protoreflect.Message {
	mi := &file_device_v1alpha1_gpu_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GpuSpec.ProtoReflect.Descriptor instead.
func (*GpuSpec) Descriptor() ([]byte, []int) {
	return file_device_v1alpha1_gpu_proto_rawDescGZIP(), []int{2}
}

func (x *GpuSpec) GetUuid() string {
	if x != nil {
		return x.Uuid
	}
	return ""
}

// GpuStatus defines the observed state of the GPU.
type GpuStatus struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// conditions represent the observations of this GPU's current state.
	Conditions []*Condition `protobuf:"bytes,1,rep,name=conditions,proto3" json:"conditions,omitempty"`
	// recommended_action is a suggestion for resolving the current negative state.
	RecommendedAction string `protobuf:"bytes,2,opt,name=recommended_action,json=recommendedAction,proto3" json:"recommended_action,omitempty"`
	unknownFields     protoimpl.UnknownFields
	sizeCache         protoimpl.SizeCache
}

func (x *GpuStatus) Reset() {
	*x = GpuStatus{}
	mi := &file_device_v1alpha1_gpu_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GpuStatus) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GpuStatus) ProtoMessage() {}

func (x *GpuStatus) ProtoReflect() protoreflect.Message {
	mi := &file_device_v1alpha1_gpu_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GpuStatus.ProtoReflect.Descriptor instead.
func (*GpuStatus) Descriptor() ([]byte, []int) {
	return file_device_v1alpha1_gpu_proto_rawDescGZIP(), []int{3}
}

func (x *GpuStatus) GetConditions() []*Condition {
	if x != nil {
		return x.Conditions
	}
	return nil
}

func (x *GpuStatus) GetRecommendedAction() string {
	if x != nil {
		return x.RecommendedAction
	}
	return ""
}

// Condition contains details for one aspect of the current state of a GPU.
type Condition struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// type describes the category of the condition.
	//
	// Format: CamelCase or a domain-prefixed string (e.g., foo.example.com/CamelCase)
	Type string `protobuf:"bytes,1,opt,name=type,proto3" json:"type,omitempty"`
	// status of the condition.
	//
	// Valid values: "True", "False", "Unknown".
	Status string `protobuf:"bytes,2,opt,name=status,proto3" json:"status,omitempty"`
	// last_transition_time is the timestamp corresponding to the last time the condition transitioned from one status to another.
	LastTransitionTime *timestamppb.Timestamp `protobuf:"bytes,3,opt,name=last_transition_time,json=lastTransitionTime,proto3" json:"last_transition_time,omitempty"`
	// reason is a machine-readable, UpperCamelCase text string indicating the reason for the condition's last transition.
	Reason string `protobuf:"bytes,4,opt,name=reason,proto3" json:"reason,omitempty"`
	// message is a human-readable message indicating details about the transition.
	Message       string `protobuf:"bytes,5,opt,name=message,proto3" json:"message,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Condition) Reset() {
	*x = Condition{}
	mi := &file_device_v1alpha1_gpu_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Condition) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Condition) ProtoMessage() {}

func (x *Condition) ProtoReflect() protoreflect.Message {
	mi := &file_device_v1alpha1_gpu_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Condition.ProtoReflect.Descriptor instead.
func (*Condition) Descriptor() ([]byte, []int) {
	return file_device_v1alpha1_gpu_proto_rawDescGZIP(), []int{4}
}

func (x *Condition) GetType() string {
	if x != nil {
		return x.Type
	}
	return ""
}

func (x *Condition) GetStatus() string {
	if x != nil {
		return x.Status
	}
	return ""
}

func (x *Condition) GetLastTransitionTime() *timestamppb.Timestamp {
	if x != nil {
		return x.LastTransitionTime
	}
	return nil
}

func (x *Condition) GetReason() string {
	if x != nil {
		return x.Reason
	}
	return ""
}

func (x *Condition) GetMessage() string {
	if x != nil {
		return x.Message
	}
	return ""
}

// GetGpuRequest specifies the GPU to retrieve.
type GetGpuRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The unique resource name of the GPU to retrieve.
	Name          string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetGpuRequest) Reset() {
	*x = GetGpuRequest{}
	mi := &file_device_v1alpha1_gpu_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetGpuRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetGpuRequest) ProtoMessage() {}

func (x *GetGpuRequest) ProtoReflect() protoreflect.Message {
	mi := &file_device_v1alpha1_gpu_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetGpuRequest.ProtoReflect.Descriptor instead.
func (*GetGpuRequest) Descriptor() ([]byte, []int) {
	return file_device_v1alpha1_gpu_proto_rawDescGZIP(), []int{5}
}

func (x *GetGpuRequest) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

// GetGpuResponse contains the requested GPU resource.
type GetGpuResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// gpu is the requested GPU resource.
	Gpu           *Gpu `protobuf:"bytes,1,opt,name=gpu,proto3" json:"gpu,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetGpuResponse) Reset() {
	*x = GetGpuResponse{}
	mi := &file_device_v1alpha1_gpu_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetGpuResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetGpuResponse) ProtoMessage() {}

func (x *GetGpuResponse) ProtoReflect() protoreflect.Message {
	mi := &file_device_v1alpha1_gpu_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetGpuResponse.ProtoReflect.Descriptor instead.
func (*GetGpuResponse) Descriptor() ([]byte, []int) {
	return file_device_v1alpha1_gpu_proto_rawDescGZIP(), []int{6}
}

func (x *GetGpuResponse) GetGpu() *Gpu {
	if x != nil {
		return x.Gpu
	}
	return nil
}

// ListGpusRequest specifies the criteria for listing GPU resources.
//
// NOTE: The request is currently empty, but reserved for future support
// of filtering and pagination.
type ListGpusRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListGpusRequest) Reset() {
	*x = ListGpusRequest{}
	mi := &file_device_v1alpha1_gpu_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListGpusRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListGpusRequest) ProtoMessage() {}

func (x *ListGpusRequest) ProtoReflect() protoreflect.Message {
	mi := &file_device_v1alpha1_gpu_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListGpusRequest.ProtoReflect.Descriptor instead.
func (*ListGpusRequest) Descriptor() ([]byte, []int) {
	return file_device_v1alpha1_gpu_proto_rawDescGZIP(), []int{7}
}

// ListGpusResponse contains the list of GPU resources.
type ListGpusResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// gpu_list contains the list of retrieved GPU resources.
	GpuList       *GpuList `protobuf:"bytes,1,opt,name=gpu_list,json=gpuList,proto3" json:"gpu_list,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListGpusResponse) Reset() {
	*x = ListGpusResponse{}
	mi := &file_device_v1alpha1_gpu_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListGpusResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListGpusResponse) ProtoMessage() {}

func (x *ListGpusResponse) ProtoReflect() protoreflect.Message {
	mi := &file_device_v1alpha1_gpu_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListGpusResponse.ProtoReflect.Descriptor instead.
func (*ListGpusResponse) Descriptor() ([]byte, []int) {
	return file_device_v1alpha1_gpu_proto_rawDescGZIP(), []int{8}
}

func (x *ListGpusResponse) GetGpuList() *GpuList {
	if x != nil {
		return x.GpuList
	}
	return nil
}

// WatchGpusRequest specifies the parameters for the watch stream.
//
// NOTE: The request is currently empty, but reserved for future support
// of filtering and resource versioning (resumption).
type WatchGpusRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *WatchGpusRequest) Reset() {
	*x = WatchGpusRequest{}
	mi := &file_device_v1alpha1_gpu_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *WatchGpusRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*WatchGpusRequest) ProtoMessage() {}

func (x *WatchGpusRequest) ProtoReflect() protoreflect.Message {
	mi := &file_device_v1alpha1_gpu_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use WatchGpusRequest.ProtoReflect.Descriptor instead.
func (*WatchGpusRequest) Descriptor() ([]byte, []int) {
	return file_device_v1alpha1_gpu_proto_rawDescGZIP(), []int{9}
}

// WatchGpusResponse describes a change event for a GPU resource.
type WatchGpusResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// type indicates the nature of the change.
	//
	// Valid values:
	//   - "ADDED": The GPU resource was created or first observed.
	//   - "MODIFIED": The GPU resource was updated.
	//   - "DELETED": The GPU resource was removed.
	//   - "ERROR": An error occurred during the watch stream.
	Type string `protobuf:"bytes,1,opt,name=type,proto3" json:"type,omitempty"`
	// object is the GPU resource.
	//
	// For "DELETED", this contains the last known state.
	// For "ERROR", this may be empty or contain partial data.
	Object        *Gpu `protobuf:"bytes,2,opt,name=object,proto3" json:"object,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *WatchGpusResponse) Reset() {
	*x = WatchGpusResponse{}
	mi := &file_device_v1alpha1_gpu_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *WatchGpusResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*WatchGpusResponse) ProtoMessage() {}

func (x *WatchGpusResponse) ProtoReflect() protoreflect.Message {
	mi := &file_device_v1alpha1_gpu_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use WatchGpusResponse.ProtoReflect.Descriptor instead.
func (*WatchGpusResponse) Descriptor() ([]byte, []int) {
	return file_device_v1alpha1_gpu_proto_rawDescGZIP(), []int{10}
}

func (x *WatchGpusResponse) GetType() string {
	if x != nil {
		return x.Type
	}
	return ""
}

func (x *WatchGpusResponse) GetObject() *Gpu {
	if x != nil {
		return x.Object
	}
	return nil
}

var File_device_v1alpha1_gpu_proto protoreflect.FileDescriptor

const file_device_v1alpha1_gpu_proto_rawDesc = "" +
	"\n" +
	"\x19device/v1alpha1/gpu.proto\x12\x1anvidia.nvsentinel.v1alpha1\x1a\x1fgoogle/protobuf/timestamp.proto\"\x91\x01\n" +
	"\x03Gpu\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x127\n" +
	"\x04spec\x18\x02 \x01(\v2#.nvidia.nvsentinel.v1alpha1.GpuSpecR\x04spec\x12=\n" +
	"\x06status\x18\x03 \x01(\v2%.nvidia.nvsentinel.v1alpha1.GpuStatusR\x06status\"@\n" +
	"\aGpuList\x125\n" +
	"\x05items\x18\x01 \x03(\v2\x1f.nvidia.nvsentinel.v1alpha1.GpuR\x05items\"\x1d\n" +
	"\aGpuSpec\x12\x12\n" +
	"\x04uuid\x18\x01 \x01(\tR\x04uuid\"\x81\x01\n" +
	"\tGpuStatus\x12E\n" +
	"\n" +
	"conditions\x18\x01 \x03(\v2%.nvidia.nvsentinel.v1alpha1.ConditionR\n" +
	"conditions\x12-\n" +
	"\x12recommended_action\x18\x02 \x01(\tR\x11recommendedAction\"\xb7\x01\n" +
	"\tCondition\x12\x12\n" +
	"\x04type\x18\x01 \x01(\tR\x04type\x12\x16\n" +
	"\x06status\x18\x02 \x01(\tR\x06status\x12L\n" +
	"\x14last_transition_time\x18\x03 \x01(\v2\x1a.google.protobuf.TimestampR\x12lastTransitionTime\x12\x16\n" +
	"\x06reason\x18\x04 \x01(\tR\x06reason\x12\x18\n" +
	"\amessage\x18\x05 \x01(\tR\amessage\"#\n" +
	"\rGetGpuRequest\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\"C\n" +
	"\x0eGetGpuResponse\x121\n" +
	"\x03gpu\x18\x01 \x01(\v2\x1f.nvidia.nvsentinel.v1alpha1.GpuR\x03gpu\"\x11\n" +
	"\x0fListGpusRequest\"R\n" +
	"\x10ListGpusResponse\x12>\n" +
	"\bgpu_list\x18\x01 \x01(\v2#.nvidia.nvsentinel.v1alpha1.GpuListR\agpuList\"\x12\n" +
	"\x10WatchGpusRequest\"`\n" +
	"\x11WatchGpusResponse\x12\x12\n" +
	"\x04type\x18\x01 \x01(\tR\x04type\x127\n" +
	"\x06object\x18\x02 \x01(\v2\x1f.nvidia.nvsentinel.v1alpha1.GpuR\x06object2\xc0\x02\n" +
	"\n" +
	"GpuService\x12_\n" +
	"\x06GetGpu\x12).nvidia.nvsentinel.v1alpha1.GetGpuRequest\x1a*.nvidia.nvsentinel.v1alpha1.GetGpuResponse\x12e\n" +
	"\bListGpus\x12+.nvidia.nvsentinel.v1alpha1.ListGpusRequest\x1a,.nvidia.nvsentinel.v1alpha1.ListGpusResponse\x12j\n" +
	"\tWatchGpus\x12,.nvidia.nvsentinel.v1alpha1.WatchGpusRequest\x1a-.nvidia.nvsentinel.v1alpha1.WatchGpusResponse0\x01BBZ@github.com/nvidia/nvsentinel/api/gen/go/device/v1alpha1;v1alpha1b\x06proto3"

var (
	file_device_v1alpha1_gpu_proto_rawDescOnce sync.Once
	file_device_v1alpha1_gpu_proto_rawDescData []byte
)

func file_device_v1alpha1_gpu_proto_rawDescGZIP() []byte {
	file_device_v1alpha1_gpu_proto_rawDescOnce.Do(func() {
		file_device_v1alpha1_gpu_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_device_v1alpha1_gpu_proto_rawDesc), len(file_device_v1alpha1_gpu_proto_rawDesc)))
	})
	return file_device_v1alpha1_gpu_proto_rawDescData
}

var file_device_v1alpha1_gpu_proto_msgTypes = make([]protoimpl.MessageInfo, 11)
var file_device_v1alpha1_gpu_proto_goTypes = []any{
	(*Gpu)(nil),                   // 0: nvidia.nvsentinel.v1alpha1.Gpu
	(*GpuList)(nil),               // 1: nvidia.nvsentinel.v1alpha1.GpuList
	(*GpuSpec)(nil),               // 2: nvidia.nvsentinel.v1alpha1.GpuSpec
	(*GpuStatus)(nil),             // 3: nvidia.nvsentinel.v1alpha1.GpuStatus
	(*Condition)(nil),             // 4: nvidia.nvsentinel.v1alpha1.Condition
	(*GetGpuRequest)(nil),         // 5: nvidia.nvsentinel.v1alpha1.GetGpuRequest
	(*GetGpuResponse)(nil),        // 6: nvidia.nvsentinel.v1alpha1.GetGpuResponse
	(*ListGpusRequest)(nil),       // 7: nvidia.nvsentinel.v1alpha1.ListGpusRequest
	(*ListGpusResponse)(nil),      // 8: nvidia.nvsentinel.v1alpha1.ListGpusResponse
	(*WatchGpusRequest)(nil),      // 9: nvidia.nvsentinel.v1alpha1.WatchGpusRequest
	(*WatchGpusResponse)(nil),     // 10: nvidia.nvsentinel.v1alpha1.WatchGpusResponse
	(*timestamppb.Timestamp)(nil), // 11: google.protobuf.Timestamp
}
var file_device_v1alpha1_gpu_proto_depIdxs = []int32{
	2,  // 0: nvidia.nvsentinel.v1alpha1.Gpu.spec:type_name -> nvidia.nvsentinel.v1alpha1.GpuSpec
	3,  // 1: nvidia.nvsentinel.v1alpha1.Gpu.status:type_name -> nvidia.nvsentinel.v1alpha1.GpuStatus
	0,  // 2: nvidia.nvsentinel.v1alpha1.GpuList.items:type_name -> nvidia.nvsentinel.v1alpha1.Gpu
	4,  // 3: nvidia.nvsentinel.v1alpha1.GpuStatus.conditions:type_name -> nvidia.nvsentinel.v1alpha1.Condition
	11, // 4: nvidia.nvsentinel.v1alpha1.Condition.last_transition_time:type_name -> google.protobuf.Timestamp
	0,  // 5: nvidia.nvsentinel.v1alpha1.GetGpuResponse.gpu:type_name -> nvidia.nvsentinel.v1alpha1.Gpu
	1,  // 6: nvidia.nvsentinel.v1alpha1.ListGpusResponse.gpu_list:type_name -> nvidia.nvsentinel.v1alpha1.GpuList
	0,  // 7: nvidia.nvsentinel.v1alpha1.WatchGpusResponse.object:type_name -> nvidia.nvsentinel.v1alpha1.Gpu
	5,  // 8: nvidia.nvsentinel.v1alpha1.GpuService.GetGpu:input_type -> nvidia.nvsentinel.v1alpha1.GetGpuRequest
	7,  // 9: nvidia.nvsentinel.v1alpha1.GpuService.ListGpus:input_type -> nvidia.nvsentinel.v1alpha1.ListGpusRequest
	9,  // 10: nvidia.nvsentinel.v1alpha1.GpuService.WatchGpus:input_type -> nvidia.nvsentinel.v1alpha1.WatchGpusRequest
	6,  // 11: nvidia.nvsentinel.v1alpha1.GpuService.GetGpu:output_type -> nvidia.nvsentinel.v1alpha1.GetGpuResponse
	8,  // 12: nvidia.nvsentinel.v1alpha1.GpuService.ListGpus:output_type -> nvidia.nvsentinel.v1alpha1.ListGpusResponse
	10, // 13: nvidia.nvsentinel.v1alpha1.GpuService.WatchGpus:output_type -> nvidia.nvsentinel.v1alpha1.WatchGpusResponse
	11, // [11:14] is the sub-list for method output_type
	8,  // [8:11] is the sub-list for method input_type
	8,  // [8:8] is the sub-list for extension type_name
	8,  // [8:8] is the sub-list for extension extendee
	0,  // [0:8] is the sub-list for field type_name
}

func init() { file_device_v1alpha1_gpu_proto_init() }
func file_device_v1alpha1_gpu_proto_init() {
	if File_device_v1alpha1_gpu_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_device_v1alpha1_gpu_proto_rawDesc), len(file_device_v1alpha1_gpu_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   11,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_device_v1alpha1_gpu_proto_goTypes,
		DependencyIndexes: file_device_v1alpha1_gpu_proto_depIdxs,
		MessageInfos:      file_device_v1alpha1_gpu_proto_msgTypes,
	}.Build()
	File_device_v1alpha1_gpu_proto = out.File
	file_device_v1alpha1_gpu_proto_goTypes = nil
	file_device_v1alpha1_gpu_proto_depIdxs = nil
}
